input{
	kafka{
		bootstrap_servers=>["192.168.3.132:9092"]
		client_id=>"test"
		group_id=>"test"
		auto_offset_reset=>"latest"
		consumer_threads=>5
		decorate_events=>true
#		topics=>["kafk-gw","kafka-server"]
		topics_pattern=>"kafka-.*"
		type=>"kafka"
	}
}

filter{
	dissect{
		mapping=>{
			"message"=>"%{logdate} %{+logdate} %{src} [%{level}] %{thread} %{classline} - %{msg}"
		}
	}
	
	if [src] == "[gwlog]" {
		dissect{
			mapping=>{
				"msg"=>"%{model} %{sn} %{level} [date:%{logdate}]:%{classline} %{msg}"
			}
		}

                mutate{
			remove_field=>["@version","host","message","@timestamp"]
		}
		
		date{
			match=>["logdate","yyyy-MM-dd HH:mm:ss.SSS","UNIX","yyyy.MM.dd HH:mm:ss"]
			target=>"@timestamp"
		}
		ruby{
			code=>"event.set('logdate',event.get('@timestamp').time.localtime + 8*60*60)"
		}
	} else {
		dissect{
			mapping=>{
				"src"=>"[IP:%{ip}/%{src}]"
			}
		}
		
		mutate{
			remove_field=>["@version","host","message","@timestamp"]
		}
		date{
			match=>["logdate","yyyy-MM-dd HH:mm:ss.SSS"]
		}
	}
}

output{
	if [src] == "[gwlog]" {
		elasticsearch{
			hosts=>["192.168.3.132:9200"]
			index=>"gwlog"
			timeout=>300
		}
	} else {
		elasticsearch{
			hosts=>["192.168.3.132:9200"]
			index=>"%{src}"
			timeout=>300
		}
	}
	
	if [level] in ["WARN","ERROR","FATAL"] {
		email{
			port=>"25"
			address=>"smtp.qq.com"
			username=>"2509569172@qq.com"
			password=>"vvaivsnyfhpmdjah"
			authentication=>"plain"
			use_tls=>false
			from=>"2509569172@qq.com"
			subject=>"warning: program have error!"
			to=>"baijun@kaadas.com"
			via=>"smtp"
			body=>"%{src},%{classline},%{msg}"
		}
	}
}
